{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RWBY Wiki Scraper.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xcsix_55lJOF"
      },
      "source": [
        "# RWBY Wiki Scraper\r\n",
        "This jupyter notebook can be used to scrape the transcipts of all the episodes from the RWBY Wiki. Run all of the cells to obtain .json files for the transcripts. I'll give a short description of what each cell does."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv4xe9BomFIV"
      },
      "source": [
        "Running this cell will create the necessary directory structure required by the scripts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nxFHEH9mKPM"
      },
      "source": [
        "!mkdir 'Main Series'\r\n",
        "!mkdir 'Main Series/V1'\r\n",
        "!mkdir 'Main Series/V2'\r\n",
        "!mkdir 'Main Series/V3'\r\n",
        "!mkdir 'Main Series/V4'\r\n",
        "!mkdir 'Main Series/V5'\r\n",
        "!mkdir 'Main Series/V6'\r\n",
        "!mkdir 'Main Series/V7'\r\n",
        "!mkdir 'Main Series/V8'\r\n",
        "!mkdir Chibi\r\n",
        "!mkdir 'Chibi/S1'\r\n",
        "!mkdir 'Chibi/S2'\r\n",
        "!mkdir 'Chibi/S3'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfJov2H3n4QE"
      },
      "source": [
        "`test_if_valid(test_url)` takes the url of the main wiki page of a given episode and returns the season number and episode number. For episodes which do not belong to either the main series or RWBY Chibi (like the Red Trailer or the World of Remnant episodes), the function returns `'Special'` to differentiate it.\r\n",
        "\r\n",
        "Example Output:\r\n",
        "1. `test_if_valid('https://rwby.fandom.com/wiki/War_(episode)')` will return `'V8E7'` as its output.\r\n",
        "2. `test_if_valid('https://rwby.fandom.com/wiki/Geist_Buster')` will return `'S2E2'` as its output. Note that episodes from the main series use 'V' to indicate the season while episodes from RWBY Chibi use 'S' to indicate season. This can be used to differentiate between episodes of the two series.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnkEAQOQlCmw"
      },
      "source": [
        "import requests\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "def test_if_valid(test_url):\r\n",
        "  test_page=requests.get(test_url)\r\n",
        "  test_soup=BeautifulSoup(test_page.content, 'html.parser')\r\n",
        "  test_main_link=test_soup.find('div', class_='page-header__page-subtitle')\r\n",
        "  if test_main_link==None:\r\n",
        "    return 'Special'\r\n",
        "  test_back_page=test_main_link.find('a')\r\n",
        "  if test_back_page==None:\r\n",
        "    return 'Special'\r\n",
        "  test_back_url='https://rwby.fandom.com'+test_back_page['href']\r\n",
        "  test_page_back=requests.get(test_back_url)\r\n",
        "  test_pbsoup=BeautifulSoup(test_page_back.content, 'html.parser')\r\n",
        "  ul=test_pbsoup.find('ul', class_='categories')\r\n",
        "  if ul==None:\r\n",
        "    return 'Special'\r\n",
        "  check=ul.find_all('a')\r\n",
        "  if check==None:\r\n",
        "    return 'Special'\r\n",
        "  proxy=check[0]\r\n",
        "  for c in check:\r\n",
        "    if c['title']=='Category:RWBY Chibi episodes':\r\n",
        "      proxy=c['title']\r\n",
        "      break\r\n",
        "    if c['title']=='Category:Episodes':\r\n",
        "      proxy=c['title']\r\n",
        "      break\r\n",
        "  if proxy=='Category:RWBY Chibi episodes':\r\n",
        "    td=test_pbsoup.find_all('td', class_='pi-horizontal-group-item pi-data-value pi-font pi-border-color pi-item-spacing')\r\n",
        "    season=td[0].getText()\r\n",
        "    episode=td[1].getText()\r\n",
        "    return 'S'+str(season)+'E'+str(episode)\r\n",
        "  elif proxy=='Category:Episodes':\r\n",
        "    td=test_pbsoup.find_all('td', class_='pi-horizontal-group-item pi-data-value pi-font pi-border-color pi-item-spacing')\r\n",
        "    volume=td[0].find('a').getText()\r\n",
        "    episode=td[1].getText()\r\n",
        "    return 'V'+str(volume)+'E'+str(episode)\r\n",
        "  else:\r\n",
        "    return 'Special'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rttMx39llH-s"
      },
      "source": [
        "`get_dialogue(url)` takes the link of the wiki page of the transcript as input and returns the dialogue as a list of lines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXfRLAdDlN3F"
      },
      "source": [
        "import requests\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "def get_dialogue(url):\r\n",
        "  page=requests.get(url)\r\n",
        "  soup=BeautifulSoup(page.content, 'html.parser')\r\n",
        "  div=soup.find('div', class_='mw-parser-output')\r\n",
        "  paras=div.find_all('p')\r\n",
        "  text=[]\r\n",
        "  for p in paras:\r\n",
        "    text.append(p.getText())\r\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vf5A76X-lOGa"
      },
      "source": [
        "Running this cell will save the .json files for each episode. It currently makes a request to the wiki every 1 second, so it should take around 3-4 minutes to finish running. I couldn't find any details about how frequently requests can be made to the fandom website, so do let me know if there are any official guidelines for bots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2toDNuSlOaj"
      },
      "source": [
        "import requests\r\n",
        "import json\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "from time import sleep\r\n",
        "transcripts_url='https://rwby.fandom.com/wiki/Category:Transcripts'\r\n",
        "transcripts_page=requests.get(transcripts_url)\r\n",
        "soup=BeautifulSoup(transcripts_page.content, 'html.parser')\r\n",
        "results=soup.find(id='mw-content-text')\r\n",
        "links=results.find_all('a', class_='category-page__member-link')\r\n",
        "i=0\r\n",
        "for link in links:\r\n",
        "  url='https://rwby.fandom.com'+link['href']\r\n",
        "  print(i)\r\n",
        "  i+=1\r\n",
        "  sleep(1)\r\n",
        "  test=test_if_valid(url)\r\n",
        "  if test!='Special':\r\n",
        "    text=get_dialogue(url)  \r\n",
        "    if test[0]=='S':   \r\n",
        "      with open('/content/Chibi/S'+str(test[1])+'/'+test+'.json', 'w') as json_file:\r\n",
        "        json.dump(text, json_file)\r\n",
        "    else:\r\n",
        "      with open('/content/Main Series/V'+str(test[1])+'/'+test+'.json', 'w') as json_file:\r\n",
        "        json.dump(text, json_file)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}